{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['[WinError 127] The specified procedure could not be found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e609ceb2d849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;31m# load the XGBoost library globally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;34m'libgomp.so for UNIX-like OSes)\\n'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: XGBoost Library (xgboost.dll) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libgomp.so for UNIX-like OSes)\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['[WinError 127] The specified procedure could not be found']\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "import pandas_profiling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm # import statsmodels \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "#https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "#todo: add adjusted r2\n",
    "from sklearn.metrics import explained_variance_score,mean_absolute_error,mean_squared_error,mean_squared_log_error,r2_score\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalRegressor(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    evs = explained_variance_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    msl = 0\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    Ar2 = 1-(1-r2)*(len(y_test)-1)/(len(y_test)-x_test.shape[1]-1)\n",
    "    return y_pred,evs,mae,mse,msl,r2,Ar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['price']\n",
    "del df['availability_30']\n",
    "del df['availability_365']\n",
    "del df['availability_60']\n",
    "del df['availability_90']\n",
    "del df['Occupy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoNA = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XNoNA = dfNoNA.drop(['Income_per_month'], axis=1)\n",
    "yNoNA = dfNoNA['Income_per_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainNoNA, X_testNoNA, y_trainNoNA, y_testNoNA = train_test_split(XNoNA, yNoNA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Income_per_month'], axis=1)\n",
    "y = df['Income_per_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = LinearRegression()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "ridge = Ridge(random_state=1)\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "stregr = StackingRegressor(regressors=[svr_lin, lr, ridge], \n",
    "                           meta_regressor=svr_rbf)\n",
    "\n",
    "# Training the stacking classifier\n",
    "\n",
    "stregr.fit(X, y)\n",
    "stregr.predict(X)\n",
    "\n",
    "# Evaluate and visualize the fit\n",
    "\n",
    "print(\"Mean Squared Error: %.4f\"\n",
    "      % np.mean((stregr.predict(X) - y) ** 2))\n",
    "print('Variance Score: %.4f' % stregr.score(X, y))\n",
    "\n",
    "with plt.style.context(('seaborn-whitegrid')):\n",
    "    plt.scatter(X, y, c='lightgray')\n",
    "    plt.plot(X, stregr.predict(X), c='darkgreen', lw=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing models\n",
    "RF = RandomForestRegressor()\n",
    "XGB = XGBRegressor(nthread=-1)\n",
    "CB = cb.CatBoostRegressor()\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "regressors = [RF,svr_lin,XGB,CB,]\n",
    "stregr = StackingRegressor(regressors=regressors, \n",
    "                           meta_regressor=svr_rbf)\n",
    "\n",
    "\n",
    "params = {  'RF__max_depth': [3, 4, 5, None,10],\n",
    "            'RF__n_estimators': [10, 100, 200, 400,600,1000],\n",
    "            'RF__max_features': [2,4,6,10,15,30,50],\n",
    "            'RF__min_samples_leaf': [1,3,5,10,50,30],\n",
    "            'CB__depth':[3,1,6,10],\n",
    "            'CB__iterations':[100],\n",
    "            'CB__learning_rate':[0.0001,0.03,0.001,0.01,0.1,0.3], \n",
    "            'CB__l2_leaf_reg':[3,1,5,10,40],\n",
    "            'CB__border_count':[32,5,20,50,100],\n",
    "          #'ctr_border_count':[50,5,10,20,100,200],\n",
    "            'CB__thread_count':[4],\n",
    "            'XGB__min_child_weight':[3,4,5], \n",
    "            'XGB__gamma':[i/10.0 for i in range(1,6)],\n",
    "            'XGB__subsample':[i/10.0 for i in range(6,11)],\n",
    "            'XGB__colsample_bytree':[i/10.0 for i in range(6,11)],\n",
    "            'XGB__max_depth': [4,5,6]\n",
    "            'meta_regressor__C': [0.1, 1.0, 10.0, 100.0],\n",
    "            'meta_regressor__gamma': [0.1, 1.0, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=stregr, \n",
    "                    param_grid=params, \n",
    "                    cv=5,\n",
    "                    refit=True)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelXGB = pickle.load(open('Final_CLF_XGB.sav','rb'))\n",
    "modelRF = pickle.load(open('Final_CLF_RF.sav','rb'))\n",
    "modelCAT = pickle.load(open('Final_CLF_CAT.sav','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predXGB = modelXGB.predict(x_trainNoNA)\n",
    "predRF = modelRF.predict(x_trainNoNA)\n",
    "predCAT = modelCAT.predict(x_trainNoNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(\n",
    "    {'predXGB': predXGB,\n",
    "     'predRF': predRF,\n",
    "     'predCAT': predCAT\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf')\n",
    "svr_rbf.fit(preds, y_trainNoNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = pd.DataFrame(\n",
    "    {'predXGB': modelXGB.predict(x_testNoNA),\n",
    "     'predRF': modelRF.predict(x_testNoNA),\n",
    "     'predCAT': modelCAT.predict(x_testNoNA)\n",
    "    })\n",
    "y_pred_XGB,evs_XGB,mae_XGB,mse_XGB,msl_XGB,r2_XGB,Ar2_XGB = evalRegressor(svr_rbf,preds_test, y_testNoNA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB,evs_XGB,mae_XGB,mse_XGB,msl_XGB,r2_XGB,Ar2_XGB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
